{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習內容』\n",
    "#### 運用這幾天所學觀念搭建一個CNN分類器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習目的』\n",
    "  #### 熟悉CNN分類器搭建步驟與原理\n",
    "  #### 學員們可以嘗試不同搭法，如使用不同的Maxpooling層，用GlobalAveragePooling取代Flatten等等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0313 22:49:02.439795 140391705737024 __init__.py:308] Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder  # pip install -U scikit-learn scipy matplotlib\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(x_train.shape)  # (50000, 32, 32, 3)\n",
    "\n",
    "## Normalize Data\n",
    "def normalize(X_train, X_test):\n",
    "        mean = np.mean(X_train, axis=(0, 1, 2, 3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7) \n",
    "        return X_train, X_test, mean, std\n",
    "    \n",
    "## Normalize Training and Testset    \n",
    "x_train, x_test, mean_train, std_train = normalize(x_train, x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OneHot Label 由(None, 1)-(None, 10)\n",
    "## ex. label=2, 變成[0,0,1,0,0,0,0,0,0,0]\n",
    "\n",
    "one_hot = OneHotEncoder()\n",
    "# fit_transform 是做 fit 和 transform 兩個動作，在 y_train 時已經 fit 過，所以 y_test 只要 transform 就好\n",
    "y_train = one_hot.fit_transform(y_train).toarray()\n",
    "y_test = one_hot.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0313 22:49:12.391528 140391705737024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0313 22:49:12.400820 140391705737024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0313 22:49:12.441749 140391705737024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0313 22:49:12.458996 140391705737024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0313 22:49:12.459447 140391705737024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0313 22:49:13.102722 140391705737024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0313 22:49:13.147369 140391705737024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", kernel_regularizer=<keras.reg..., units=100)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.5)`\n",
      "W0313 22:49:13.276392 140391705737024 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", kernel_regularizer=<keras.reg..., units=100)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.3)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n",
      "W0313 22:49:13.369246 140391705737024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0313 22:49:14.769431 140391705737024 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "500/500 [==============================] - 18s 36ms/step - loss: 2.0952 - acc: 0.3565 - val_loss: 1.5795 - val_acc: 0.5148\n",
      "Epoch 2/100\n",
      " 15/500 [..............................] - ETA: 6s - loss: 1.7809 - acc: 0.4427"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:569: RuntimeWarning: Early stopping conditioned on metric `test_loss` which is not available. Available metrics are: val_loss,val_acc,loss,acc\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 16s 33ms/step - loss: 1.6577 - acc: 0.4840 - val_loss: 1.4011 - val_acc: 0.5617\n",
      "Epoch 3/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.4734 - acc: 0.5403 - val_loss: 1.3037 - val_acc: 0.5966\n",
      "Epoch 4/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.3728 - acc: 0.5700 - val_loss: 1.2362 - val_acc: 0.6111\n",
      "Epoch 5/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.3038 - acc: 0.5892 - val_loss: 1.1680 - val_acc: 0.6300\n",
      "Epoch 6/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.2593 - acc: 0.6041 - val_loss: 1.2046 - val_acc: 0.6220\n",
      "Epoch 7/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.2245 - acc: 0.6153 - val_loss: 1.1577 - val_acc: 0.6347\n",
      "Epoch 8/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.1977 - acc: 0.6254 - val_loss: 1.0429 - val_acc: 0.6744\n",
      "Epoch 9/100\n",
      "500/500 [==============================] - 16s 32ms/step - loss: 1.1818 - acc: 0.6267 - val_loss: 1.0378 - val_acc: 0.6749\n",
      "Epoch 10/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.1675 - acc: 0.6349 - val_loss: 1.0379 - val_acc: 0.6737\n",
      "Epoch 11/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.1488 - acc: 0.6388 - val_loss: 1.0931 - val_acc: 0.6586\n",
      "Epoch 12/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.1409 - acc: 0.6441 - val_loss: 1.0659 - val_acc: 0.6682\n",
      "Epoch 13/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.1385 - acc: 0.6447 - val_loss: 1.0554 - val_acc: 0.6697\n",
      "Epoch 14/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.1273 - acc: 0.6505 - val_loss: 1.0886 - val_acc: 0.6639\n",
      "Epoch 15/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.1166 - acc: 0.6531 - val_loss: 1.0035 - val_acc: 0.6887\n",
      "Epoch 16/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.1058 - acc: 0.6577 - val_loss: 1.0063 - val_acc: 0.6859\n",
      "Epoch 17/100\n",
      "500/500 [==============================] - 16s 32ms/step - loss: 1.1016 - acc: 0.6598 - val_loss: 1.0297 - val_acc: 0.6824\n",
      "Epoch 18/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.0991 - acc: 0.6619 - val_loss: 0.9913 - val_acc: 0.6910\n",
      "Epoch 19/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.0889 - acc: 0.6643 - val_loss: 1.0669 - val_acc: 0.6756\n",
      "Epoch 20/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.0864 - acc: 0.6624 - val_loss: 0.9605 - val_acc: 0.7038\n",
      "Epoch 21/100\n",
      "500/500 [==============================] - 16s 32ms/step - loss: 1.0786 - acc: 0.6659 - val_loss: 1.0462 - val_acc: 0.6831\n",
      "Epoch 22/100\n",
      "500/500 [==============================] - 17s 33ms/step - loss: 1.0770 - acc: 0.6714 - val_loss: 0.9761 - val_acc: 0.7027\n",
      "Epoch 23/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.0664 - acc: 0.6729 - val_loss: 1.0461 - val_acc: 0.6831\n",
      "Epoch 24/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.0664 - acc: 0.6731 - val_loss: 0.9373 - val_acc: 0.7109\n",
      "Epoch 25/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.0599 - acc: 0.6758 - val_loss: 0.9562 - val_acc: 0.7046\n",
      "Epoch 26/100\n",
      "500/500 [==============================] - 16s 32ms/step - loss: 1.0639 - acc: 0.6741 - val_loss: 0.9391 - val_acc: 0.7116\n",
      "Epoch 27/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.0586 - acc: 0.6767 - val_loss: 0.9768 - val_acc: 0.6992\n",
      "Epoch 28/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.0478 - acc: 0.6819 - val_loss: 1.0179 - val_acc: 0.6890\n",
      "Epoch 29/100\n",
      "500/500 [==============================] - 16s 32ms/step - loss: 1.0605 - acc: 0.6754 - val_loss: 0.9614 - val_acc: 0.7058\n",
      "Epoch 30/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.0435 - acc: 0.6828 - val_loss: 0.9698 - val_acc: 0.7027\n",
      "Epoch 31/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.0471 - acc: 0.6784 - val_loss: 1.0067 - val_acc: 0.6939\n",
      "Epoch 32/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.0435 - acc: 0.6836 - val_loss: 0.9336 - val_acc: 0.7143\n",
      "Epoch 33/100\n",
      "500/500 [==============================] - 16s 32ms/step - loss: 1.0386 - acc: 0.6837 - val_loss: 0.9893 - val_acc: 0.6975\n",
      "Epoch 34/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.0353 - acc: 0.6852 - val_loss: 0.9810 - val_acc: 0.7025\n",
      "Epoch 35/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.0406 - acc: 0.6834 - val_loss: 1.0053 - val_acc: 0.6943\n",
      "Epoch 36/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.0349 - acc: 0.6843 - val_loss: 0.9698 - val_acc: 0.7022\n",
      "Epoch 37/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.0345 - acc: 0.6845 - val_loss: 0.9947 - val_acc: 0.6966\n",
      "Epoch 38/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.0274 - acc: 0.6865 - val_loss: 0.9685 - val_acc: 0.7086\n",
      "Epoch 39/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.0240 - acc: 0.6885 - val_loss: 0.9905 - val_acc: 0.7028\n",
      "Epoch 40/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.0247 - acc: 0.6882 - val_loss: 0.9557 - val_acc: 0.7097\n",
      "Epoch 41/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.0298 - acc: 0.6861 - val_loss: 1.0485 - val_acc: 0.6842\n",
      "Epoch 42/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.0201 - acc: 0.6922 - val_loss: 1.0251 - val_acc: 0.6938\n",
      "Epoch 43/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.0153 - acc: 0.6900 - val_loss: 0.9319 - val_acc: 0.7165\n",
      "Epoch 44/100\n",
      "500/500 [==============================] - 16s 32ms/step - loss: 1.0186 - acc: 0.6896 - val_loss: 1.0070 - val_acc: 0.7008\n",
      "Epoch 45/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.0144 - acc: 0.6935 - val_loss: 0.9612 - val_acc: 0.7083\n",
      "Epoch 46/100\n",
      "500/500 [==============================] - 16s 32ms/step - loss: 1.0136 - acc: 0.6935 - val_loss: 1.1272 - val_acc: 0.6725\n",
      "Epoch 47/100\n",
      "500/500 [==============================] - 16s 32ms/step - loss: 1.0205 - acc: 0.6898 - val_loss: 0.9420 - val_acc: 0.7146\n",
      "Epoch 48/100\n",
      "500/500 [==============================] - 16s 32ms/step - loss: 1.0101 - acc: 0.6938 - val_loss: 0.9519 - val_acc: 0.7120\n",
      "Epoch 49/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.0065 - acc: 0.6978 - val_loss: 1.0045 - val_acc: 0.6977\n",
      "Epoch 50/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.0110 - acc: 0.6927 - val_loss: 0.9166 - val_acc: 0.7236\n",
      "Epoch 51/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.0013 - acc: 0.6978 - val_loss: 0.9315 - val_acc: 0.7195\n",
      "Epoch 52/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.0073 - acc: 0.6956 - val_loss: 0.9662 - val_acc: 0.7103\n",
      "Epoch 53/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.0003 - acc: 0.6984 - val_loss: 0.9753 - val_acc: 0.7082\n",
      "Epoch 54/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.0049 - acc: 0.6963 - val_loss: 0.9583 - val_acc: 0.7102\n",
      "Epoch 55/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.0047 - acc: 0.6949 - val_loss: 0.9318 - val_acc: 0.7209\n",
      "Epoch 56/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.0022 - acc: 0.6964 - val_loss: 0.9324 - val_acc: 0.7189\n",
      "Epoch 57/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.0013 - acc: 0.6965 - val_loss: 0.9197 - val_acc: 0.7252\n",
      "Epoch 58/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 0.9957 - acc: 0.6992 - val_loss: 1.0036 - val_acc: 0.6976\n",
      "Epoch 59/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 0.9981 - acc: 0.6997 - val_loss: 1.0152 - val_acc: 0.6976\n",
      "Epoch 60/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 0.9933 - acc: 0.7010 - val_loss: 0.9361 - val_acc: 0.7175\n",
      "Epoch 61/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 0.9977 - acc: 0.6979 - val_loss: 0.9041 - val_acc: 0.7281\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 17s 33ms/step - loss: 0.9924 - acc: 0.7004 - val_loss: 0.9932 - val_acc: 0.7028\n",
      "Epoch 63/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 0.9881 - acc: 0.7013 - val_loss: 0.9232 - val_acc: 0.7164\n",
      "Epoch 64/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 0.9881 - acc: 0.7011 - val_loss: 1.0178 - val_acc: 0.6961\n",
      "Epoch 65/100\n",
      "500/500 [==============================] - 16s 32ms/step - loss: 0.9927 - acc: 0.7008 - val_loss: 0.9492 - val_acc: 0.7141\n",
      "Epoch 66/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 0.9892 - acc: 0.7015 - val_loss: 0.9695 - val_acc: 0.7081\n",
      "Epoch 67/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 0.9857 - acc: 0.7026 - val_loss: 0.9830 - val_acc: 0.7040\n",
      "Epoch 68/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 0.9822 - acc: 0.7018 - val_loss: 0.9288 - val_acc: 0.7217\n",
      "Epoch 69/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 0.9907 - acc: 0.6979 - val_loss: 1.0137 - val_acc: 0.6967\n",
      "Epoch 70/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 0.9898 - acc: 0.7010 - val_loss: 0.9142 - val_acc: 0.7303\n",
      "Epoch 71/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 0.9802 - acc: 0.7062 - val_loss: 1.0805 - val_acc: 0.6822\n",
      "Epoch 72/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 0.9853 - acc: 0.7018 - val_loss: 0.8866 - val_acc: 0.7339\n",
      "Epoch 73/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 0.9796 - acc: 0.7045 - val_loss: 0.9296 - val_acc: 0.7202\n",
      "Epoch 74/100\n",
      "500/500 [==============================] - 17s 33ms/step - loss: 0.9830 - acc: 0.7036 - val_loss: 1.0215 - val_acc: 0.6936\n",
      "Epoch 75/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 0.9840 - acc: 0.7021 - val_loss: 0.9722 - val_acc: 0.7079\n",
      "Epoch 76/100\n",
      "500/500 [==============================] - 17s 33ms/step - loss: 0.9773 - acc: 0.7055 - val_loss: 0.9353 - val_acc: 0.7205\n",
      "Epoch 77/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 0.9667 - acc: 0.7051 - val_loss: 0.9740 - val_acc: 0.7071\n",
      "Epoch 78/100\n",
      "500/500 [==============================] - 16s 32ms/step - loss: 0.9819 - acc: 0.7034 - val_loss: 0.8547 - val_acc: 0.7467\n",
      "Epoch 79/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 0.9749 - acc: 0.7073 - val_loss: 0.9495 - val_acc: 0.7181\n",
      "Epoch 80/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 0.9808 - acc: 0.7049 - val_loss: 0.8966 - val_acc: 0.7338\n",
      "Epoch 81/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 0.9746 - acc: 0.7073 - val_loss: 1.0298 - val_acc: 0.6986\n",
      "Epoch 82/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 0.9729 - acc: 0.7087 - val_loss: 0.9553 - val_acc: 0.7211\n",
      "Epoch 83/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 0.9730 - acc: 0.7076 - val_loss: 0.8953 - val_acc: 0.7326\n",
      "Epoch 84/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 0.9765 - acc: 0.7077 - val_loss: 0.9473 - val_acc: 0.7142\n",
      "Epoch 85/100\n",
      "500/500 [==============================] - 16s 32ms/step - loss: 0.9735 - acc: 0.7065 - val_loss: 0.9820 - val_acc: 0.7079\n",
      "Epoch 86/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 0.9692 - acc: 0.7097 - val_loss: 0.9160 - val_acc: 0.7314\n",
      "Epoch 87/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 0.9743 - acc: 0.7083 - val_loss: 0.9478 - val_acc: 0.7210\n",
      "Epoch 88/100\n",
      "500/500 [==============================] - 17s 33ms/step - loss: 0.9678 - acc: 0.7092 - val_loss: 0.8934 - val_acc: 0.7320\n",
      "Epoch 89/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 0.9720 - acc: 0.7086 - val_loss: 1.0019 - val_acc: 0.7016\n",
      "Epoch 90/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 0.9690 - acc: 0.7096 - val_loss: 0.9437 - val_acc: 0.7198\n",
      "Epoch 91/100\n",
      "500/500 [==============================] - 17s 33ms/step - loss: 0.9680 - acc: 0.7093 - val_loss: 0.9145 - val_acc: 0.7291\n",
      "Epoch 92/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 0.9747 - acc: 0.7087 - val_loss: 0.9611 - val_acc: 0.7131\n",
      "Epoch 93/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 0.9637 - acc: 0.7105 - val_loss: 1.0218 - val_acc: 0.7011\n",
      "Epoch 94/100\n",
      "500/500 [==============================] - 17s 33ms/step - loss: 0.9662 - acc: 0.7127 - val_loss: 0.9736 - val_acc: 0.7122\n",
      "Epoch 95/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 0.9658 - acc: 0.7095 - val_loss: 0.9302 - val_acc: 0.7242\n",
      "Epoch 96/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 0.9623 - acc: 0.7127 - val_loss: 0.9886 - val_acc: 0.7084\n",
      "Epoch 97/100\n",
      "500/500 [==============================] - 16s 32ms/step - loss: 0.9695 - acc: 0.7083 - val_loss: 0.9216 - val_acc: 0.7216\n",
      "Epoch 98/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 0.9651 - acc: 0.7115 - val_loss: 0.9822 - val_acc: 0.7074\n",
      "Epoch 99/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 0.9637 - acc: 0.7119 - val_loss: 0.8720 - val_acc: 0.7419\n",
      "Epoch 100/100\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 0.9658 - acc: 0.7116 - val_loss: 1.0676 - val_acc: 0.6888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fae3071ba90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "# 卷積組合\n",
    "classifier.add(Convolution2D(32, kernel_size=(3, 3), input_shape=(32, 32, 3), activation='relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# 卷積組合\n",
    "classifier.add(Convolution2D(32, kernel_size=(3, 3), input_shape=(32, 32, 3), activation='relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# flatten\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# FC\n",
    "classifier.add(Dense(output_dim=100, activation='relu', kernel_regularizer=regularizers.l2(l=0.001)))  # regularizers\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Dropout(p=0.5))\n",
    "\n",
    "classifier.add(Dense(output_dim=100, activation='relu', kernel_regularizer=regularizers.l2(0.001))) # regularizers\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Dropout(p=0.3))\n",
    "\n",
    "# 輸出\n",
    "classifier.add(Dense(output_dim=10,activation='softmax'))\n",
    "\n",
    "# 超過兩個就要選 categorical_crossentrophy\n",
    "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator  # Augmentation\n",
    "img_gen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True, rotation_range=10, \n",
    "                             width_shift_range=0.1, height_shift_range=0.1, shear_range=0.1, zoom_range=0.1, \n",
    "                             horizontal_flip=True, vertical_flip=False, dtype=np.float32)\n",
    "img_gen.fit(x_train)\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "earlystop = EarlyStopping(monitor='test_loss', patience=8, verbose=1)  # earlystop\n",
    "\n",
    "# 開始訓練\n",
    "classifier.fit_generator(img_gen.flow(x_train, y_train, batch_size=100), steps_per_epoch=500, epochs=100, \n",
    "                         validation_data=(x_test, y_test), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 預測新圖片，輸入影像前處理要與訓練時相同\n",
    "#### ((X-mean)/(std+1e-7) ):這裡的mean跟std是訓練集的\n",
    "## 維度如下方示範"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07321031, 0.00519921, 0.18618354, 0.02278091, 0.00619772,\n",
       "        0.00168585, 0.05688905, 0.00099206, 0.64560145, 0.00125985]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_example=(np.zeros(shape=(1,32,32,3))-mean_train)/(std_train+1e-7) \n",
    "classifier.predict(input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 135us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0676113273620604, 0.6888]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
